import boto3
import json
import logging
import time
from datetime import datetime, timedelta
from botocore.exceptions import ClientError
from config import Config

# ë¡œê¹… ì„¤ì • - ì¤‘ë³µ ë¡œê·¸ ë°©ì§€
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
# ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
for handler in logger.handlers[:]:
    logger.removeHandler(handler)
# ìƒˆ í•¸ë“¤ëŸ¬ ì¶”ê°€
handler = logging.StreamHandler()
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)
# ìƒìœ„ ë¡œê±°ë¡œ ì „íŒŒ ë°©ì§€
logger.propagate = False

class S3Storage:
    """
    S3ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì²˜ëŸ¼ ì‚¬ìš©í•˜ì—¬ í†µí•© ëŒ€ì‹œë³´ë“œ ê²°ê³¼ë¥¼ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤
    """
    # ë©”ëª¨ë¦¬ ìºì‹œ (í´ë˜ìŠ¤ ë³€ìˆ˜)
    _cache = {
        'collections': {},  # ì‚¬ìš©ìë³„ ì»¬ë ‰ì…˜ ëª©ë¡ ìºì‹œ
        'metadata': {},     # ë©”íƒ€ë°ì´í„° ìºì‹œ
        'data': {}          # ì„œë¹„ìŠ¤ ë°ì´í„° ìºì‹œ
    }
    
    # ìºì‹œ ë§Œë£Œ ì‹œê°„ (ì´ˆ)
    CACHE_TTL = 300  # 5ë¶„
    
    # í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìºì‹œ
    _instances = {}
    
    def __new__(cls, region=None):
        """
        ì‹±ê¸€í†¤ íŒ¨í„´ êµ¬í˜„ - ë™ì¼í•œ ë¦¬ì „ì— ëŒ€í•´ í•˜ë‚˜ì˜ ì¸ìŠ¤í„´ìŠ¤ë§Œ ìƒì„±
        """
        region_key = region or Config.AWS_REGION
        if region_key not in cls._instances:
            cls._instances[region_key] = super(S3Storage, cls).__new__(cls)
            cls._instances[region_key]._initialized = False
        return cls._instances[region_key]
    
    def __init__(self, region=None):
        """
        S3Storage í´ë˜ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            region: AWS ë¦¬ì „ (ê¸°ë³¸ê°’: Configì—ì„œ ê°€ì ¸ì˜´)
        """
        # ì´ë¯¸ ì´ˆê¸°í™”ëœ ì¸ìŠ¤í„´ìŠ¤ëŠ” ë‹¤ì‹œ ì´ˆê¸°í™”í•˜ì§€ ì•ŠìŒ
        if hasattr(self, '_initialized') and self._initialized:
            return
            
        self.region = region or Config.AWS_REGION
        self.bucket_name = Config.DATA_BUCKET_NAME
        
        # ë²„í‚· ì´ë¦„ ë¡œê¹…
        logger.info(f"S3Storage ì´ˆê¸°í™”: ë²„í‚·={self.bucket_name}, ë¦¬ì „={self.region}")
        
        # S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        try:
            self.s3_client = boto3.client(
                's3',
                region_name=self.region,
                aws_access_key_id=Config.AWS_ACCESS_KEY,
                aws_secret_access_key=Config.AWS_SECRET_KEY
            )
            # ë²„í‚·ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            self.s3_client.head_bucket(Bucket=self.bucket_name)
            logger.info(f"S3 ë²„í‚· {self.bucket_name} ì ‘ê·¼ í™•ì¸ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"S3 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ë˜ëŠ” ë²„í‚· ì ‘ê·¼ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            # ì˜¤ë¥˜ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œí‚¤ì§€ ì•Šê³  ê³„ì† ì§„í–‰ (ì‹¤íŒ¨ ì‹œ ë‚˜ì¤‘ì— ì²˜ë¦¬)
            
        self._initialized = True
    
    def _get_user_prefix(self, user_id):
        """ì‚¬ìš©ìë³„ S3 ê²½ë¡œ ì ‘ë‘ì‚¬ ìƒì„±"""
        return f"users/{user_id}/dashboard_data/"
    
    def _get_cache_key(self, key_type, user_id, collection_id=None, service_key=None):
        """ìºì‹œ í‚¤ ìƒì„±"""
        if key_type == 'collections':
            return f"collections:{user_id}"
        elif key_type == 'metadata':
            return f"metadata:{user_id}:{collection_id}"
        elif key_type == 'data':
            return f"data:{user_id}:{collection_id}:{service_key}"
        return None
    
    def _get_from_cache(self, key_type, user_id, collection_id=None, service_key=None):
        """ìºì‹œì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        cache_key = self._get_cache_key(key_type, user_id, collection_id, service_key)
        if not cache_key:
            return None, False
        
        cache_entry = S3Storage._cache.get(key_type, {}).get(cache_key)
        if not cache_entry:
            return None, False
        
        # ìºì‹œ ë§Œë£Œ í™•ì¸
        if time.time() - cache_entry['timestamp'] > S3Storage.CACHE_TTL:
            # ìºì‹œ ë§Œë£Œ
            return None, False
        
        return cache_entry['data'], True
    
    def _set_in_cache(self, key_type, user_id, data, collection_id=None, service_key=None):
        """ìºì‹œì— ë°ì´í„° ì €ì¥"""
        cache_key = self._get_cache_key(key_type, user_id, collection_id, service_key)
        if not cache_key:
            return
        
        if key_type not in S3Storage._cache:
            S3Storage._cache[key_type] = {}
        
        S3Storage._cache[key_type][cache_key] = {
            'data': data,
            'timestamp': time.time()
        }
    
    def _invalidate_cache(self, key_type, user_id, collection_id=None):
        """ìºì‹œ ë¬´íš¨í™”"""
        if key_type == 'collections':
            cache_key = self._get_cache_key('collections', user_id)
            if cache_key in S3Storage._cache.get('collections', {}):
                del S3Storage._cache['collections'][cache_key]
        elif key_type == 'all':
            # ì‚¬ìš©ìì˜ ëª¨ë“  ìºì‹œ ë¬´íš¨í™”
            for cache_type in S3Storage._cache:
                keys_to_delete = []
                for key in S3Storage._cache[cache_type]:
                    if f":{user_id}:" in key or key.endswith(f":{user_id}"):
                        keys_to_delete.append(key)
                
                for key in keys_to_delete:
                    if key in S3Storage._cache[cache_type]:
                        del S3Storage._cache[cache_type][key]
        elif collection_id:
            # íŠ¹ì • ì»¬ë ‰ì…˜ ê´€ë ¨ ìºì‹œ ë¬´íš¨í™”
            for cache_type in ['metadata', 'data']:
                keys_to_delete = []
                for key in S3Storage._cache.get(cache_type, {}):
                    if f":{user_id}:{collection_id}" in key:
                        keys_to_delete.append(key)
                
                for key in keys_to_delete:
                    if key in S3Storage._cache.get(cache_type, {}):
                        del S3Storage._cache[cache_type][key]
    
    def save_collection_data(self, user_id, collection_id, data, selected_services=None):
        """
        ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ S3ì— ì €ì¥
        
        Args:
            user_id: ì‚¬ìš©ì ID
            collection_id: ìˆ˜ì§‘ ID
            data: ì €ì¥í•  ë°ì´í„° (dict)
            selected_services: ì„ íƒëœ ì„œë¹„ìŠ¤ ëª©ë¡ (list)
            
        Returns:
            bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        try:
            # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
            timestamp = datetime.now().isoformat()
            
            # ë©”íƒ€ë°ì´í„° ìƒì„±
            metadata = {
                'user_id': user_id,
                'collection_id': collection_id,
                'timestamp': timestamp,
                'selected_services': selected_services or []
            }
            
            # ë©”íƒ€ë°ì´í„° ì €ì¥
            metadata_key = f"{self._get_user_prefix(user_id)}collections/{collection_id}/metadata.json"
            self.s3_client.put_object(
                Bucket=self.bucket_name,
                Key=metadata_key,
                Body=json.dumps(metadata),
                ContentType='application/json'
            )
            logger.info(f"ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: {metadata_key}")
            
            # ì„œë¹„ìŠ¤ ë°ì´í„° í†µí•© íŒŒì¼ ìƒì„± (ëª¨ë“  ì„œë¹„ìŠ¤ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ ì €ì¥)
            all_services_data = {}
            
            # ê° ì„œë¹„ìŠ¤ ë°ì´í„° ì²˜ë¦¬
            for service_key, service_data in data.items():
                # ë°ì´í„°ê°€ Noneì´ ì•„ë‹Œì§€ í™•ì¸
                if service_data is None:
                    logger.warning(f"ì„œë¹„ìŠ¤ {service_key}ì˜ ë°ì´í„°ê°€ Noneì…ë‹ˆë‹¤. ë¹ˆ ê°ì²´ë¡œ ì €ì¥í•©ë‹ˆë‹¤.")
                    service_data = {"status": "collected", "data": {}}
                
                # ë°ì´í„° ì§ë ¬í™” ê°€ëŠ¥í•œì§€ í™•ì¸
                try:
                    # datetime ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ëŠ” JSON ì¸ì½”ë”
                    class DateTimeEncoder(json.JSONEncoder):
                        def default(self, obj):
                            if isinstance(obj, datetime):
                                return obj.isoformat()
                            return super().default(obj)
                    
                    # í…ŒìŠ¤íŠ¸ ì§ë ¬í™” (ì˜¤ë¥˜ í™•ì¸ìš©)
                    json.dumps(service_data, cls=DateTimeEncoder)
                    
                    # í†µí•© ë°ì´í„°ì— ì¶”ê°€
                    all_services_data[service_key] = service_data
                    
                except TypeError as e:
                    logger.error(f"ì„œë¹„ìŠ¤ {service_key} ë°ì´í„° ì§ë ¬í™” ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    # ì§ë ¬í™” ë¶ˆê°€ëŠ¥í•œ ê°ì²´ê°€ ìˆëŠ” ê²½ìš° ê¸°ë³¸ ê°ì²´ë¡œ ëŒ€ì²´
                    all_services_data[service_key] = {
                        "status": "error", 
                        "message": "ì§ë ¬í™” ë¶ˆê°€ëŠ¥í•œ ë°ì´í„°", 
                        "error": str(e)
                    }
            
            # ì„ íƒëœ ì„œë¹„ìŠ¤ ì¤‘ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°ì—ë„ ë¹ˆ ê°ì²´ ì¶”ê°€
            if selected_services:
                for service_key in selected_services:
                    if service_key not in all_services_data:
                        all_services_data[service_key] = {"status": "collected", "data": {}}
            
            # í†µí•© ë°ì´í„° íŒŒì¼ ì €ì¥
            all_services_key = f"{self._get_user_prefix(user_id)}collections/{collection_id}/all_services.json"
            self.s3_client.put_object(
                Bucket=self.bucket_name,
                Key=all_services_key,
                Body=json.dumps(all_services_data, cls=DateTimeEncoder),
                ContentType='application/json'
            )
            logger.info(f"í†µí•© ì„œë¹„ìŠ¤ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {all_services_key}")
            
            # ìºì‹œ ë¬´íš¨í™” - ê¸°ì¡´ ìºì‹œ ì‚­ì œ
            self._invalidate_cache('collections', user_id)
            self._invalidate_cache('all', user_id, collection_id)
            
            # ë©”íƒ€ë°ì´í„°ë¥¼ ìºì‹œì— ì €ì¥
            self._set_in_cache('metadata', user_id, metadata, collection_id)
            logger.info(f"ğŸ’¾ ë©”íƒ€ë°ì´í„° ìºì‹œ ì €ì¥ ì™„ë£Œ: {collection_id}")
            
            # ì„œë¹„ìŠ¤ ë°ì´í„°ë¥¼ ìºì‹œì— ì €ì¥
            self._set_in_cache('data', user_id, all_services_data, collection_id, 'all')
            logger.info(f"ğŸ’¾ ì„œë¹„ìŠ¤ ë°ì´í„° ìºì‹œ ì €ì¥ ì™„ë£Œ: {collection_id}")
            
            logger.info(f"ì‚¬ìš©ì {user_id}ì˜ ìˆ˜ì§‘ ë°ì´í„° {collection_id}ë¥¼ S3ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
            return True
            
        except Exception as e:
            logger.error(f"S3ì— ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False
    
    def get_collection_data(self, user_id, collection_id):
        """
        S3ì—ì„œ íŠ¹ì • ìˆ˜ì§‘ IDì˜ ë°ì´í„° ì¡°íšŒ
        
        Args:
            user_id: ì‚¬ìš©ì ID
            collection_id: ìˆ˜ì§‘ ID
            
        Returns:
            dict: ìˆ˜ì§‘ëœ ë°ì´í„°ì™€ ë©”íƒ€ë°ì´í„°
        """
        try:
            result = {'metadata': None, 'services_data': {}}
            data_source = {'metadata': None, 'services_data': None}  # ë°ì´í„° ì†ŒìŠ¤ ì¶”ì 
            
            # ë©”íƒ€ë°ì´í„° ìºì‹œ í™•ì¸
            metadata, cache_hit = self._get_from_cache('metadata', user_id, collection_id)
            if cache_hit:
                logger.info(f"âœ… ë©”íƒ€ë°ì´í„° ìºì‹œ íˆíŠ¸ ì„±ê³µ: {collection_id}")
                result['metadata'] = metadata
                data_source['metadata'] = 'cache'
            else:
                logger.info(f"âŒ ë©”íƒ€ë°ì´í„° ìºì‹œ íˆíŠ¸ ì‹¤íŒ¨: {collection_id}")
                # ë©”íƒ€ë°ì´í„° ì¡°íšŒ
                metadata_key = f"{self._get_user_prefix(user_id)}collections/{collection_id}/metadata.json"
                logger.info(f"ğŸ“¥ S3ì—ì„œ ë©”íƒ€ë°ì´í„° ì¡°íšŒ ì‹œë„: {metadata_key}")
                
                try:
                    metadata_obj = self.s3_client.get_object(Bucket=self.bucket_name, Key=metadata_key)
                    result['metadata'] = json.loads(metadata_obj['Body'].read().decode('utf-8'))
                    logger.info(f"ğŸ“¥ S3ì—ì„œ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì„±ê³µ")
                    data_source['metadata'] = 'S3'
                    
                    # ë©”íƒ€ë°ì´í„° ìºì‹œì— ì €ì¥
                    self._set_in_cache('metadata', user_id, result['metadata'], collection_id)
                    logger.info(f"ğŸ’¾ ë©”íƒ€ë°ì´í„° ìºì‹œ ì €ì¥ ì™„ë£Œ")
                except ClientError as e:
                    if e.response['Error']['Code'] == 'NoSuchKey':
                        logger.warning(f"âŒ S3ì—ì„œ ë©”íƒ€ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {metadata_key}")
                        return None
                    else:
                        logger.error(f"âŒ S3ì—ì„œ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                        raise
            
            # ì„œë¹„ìŠ¤ ë°ì´í„° ìºì‹œ í™•ì¸
            services_data, cache_hit = self._get_from_cache('data', user_id, collection_id, 'all')
            if cache_hit:
                logger.info(f"âœ… ì„œë¹„ìŠ¤ ë°ì´í„° ìºì‹œ íˆíŠ¸ ì„±ê³µ: {collection_id}")
                result['services_data'] = services_data
                data_source['services_data'] = 'cache'
                logger.info(f"ğŸ“Š ë°ì´í„° ì†ŒìŠ¤ ìš”ì•½ - ë©”íƒ€ë°ì´í„°: {data_source['metadata']}, ì„œë¹„ìŠ¤ ë°ì´í„°: {data_source['services_data']}")
                return result
            else:
                logger.info(f"âŒ ì„œë¹„ìŠ¤ ë°ì´í„° ìºì‹œ íˆíŠ¸ ì‹¤íŒ¨: {collection_id}")
            
            # í†µí•© ì„œë¹„ìŠ¤ ë°ì´í„° íŒŒì¼ ì¡°íšŒ
            all_services_key = f"{self._get_user_prefix(user_id)}collections/{collection_id}/all_services.json"
            logger.info(f"ğŸ“¥ S3ì—ì„œ í†µí•© ì„œë¹„ìŠ¤ ë°ì´í„° ì¡°íšŒ ì‹œë„: {all_services_key}")
            
            try:
                all_services_obj = self.s3_client.get_object(Bucket=self.bucket_name, Key=all_services_key)
                result['services_data'] = json.loads(all_services_obj['Body'].read().decode('utf-8'))
                logger.info(f"ğŸ“¥ S3ì—ì„œ í†µí•© ì„œë¹„ìŠ¤ ë°ì´í„° ë¡œë“œ ì„±ê³µ")
                data_source['services_data'] = 'S3'
                
                # ì„œë¹„ìŠ¤ ë°ì´í„° ìºì‹œì— ì €ì¥
                self._set_in_cache('data', user_id, result['services_data'], collection_id, 'all')
                logger.info(f"ğŸ’¾ ì„œë¹„ìŠ¤ ë°ì´í„° ìºì‹œ ì €ì¥ ì™„ë£Œ")
                
                logger.info(f"ğŸ“Š ë°ì´í„° ì†ŒìŠ¤ ìš”ì•½ - ë©”íƒ€ë°ì´í„°: {data_source['metadata']}, ì„œë¹„ìŠ¤ ë°ì´í„°: {data_source['services_data']}")
                return result
            except ClientError as e:
                if e.response['Error']['Code'] == 'NoSuchKey':
                    logger.warning(f"âŒ S3ì—ì„œ í†µí•© ì„œë¹„ìŠ¤ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê°œë³„ ì„œë¹„ìŠ¤ íŒŒì¼ ì¡°íšŒë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                    # ì´ì „ ë°©ì‹ìœ¼ë¡œ ê°œë³„ ì„œë¹„ìŠ¤ íŒŒì¼ ì¡°íšŒ (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)
                    legacy_result = self._get_collection_data_legacy(user_id, collection_id, result)
                    if legacy_result:
                        data_source['services_data'] = 'S3 (legacy)'
                        logger.info(f"ğŸ“Š ë°ì´í„° ì†ŒìŠ¤ ìš”ì•½ - ë©”íƒ€ë°ì´í„°: {data_source['metadata']}, ì„œë¹„ìŠ¤ ë°ì´í„°: {data_source['services_data']}")
                    return legacy_result
                else:
                    logger.error(f"âŒ S3ì—ì„œ í†µí•© ì„œë¹„ìŠ¤ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    raise
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
    
    def _get_collection_data_legacy(self, user_id, collection_id, result):
        """
        ì´ì „ ë°©ì‹ìœ¼ë¡œ ê°œë³„ ì„œë¹„ìŠ¤ íŒŒì¼ ì¡°íšŒ (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)
        """
        try:
            # ì„ íƒëœ ì„œë¹„ìŠ¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            selected_services = result['metadata'].get('selected_services', [])
            logger.info(f"ğŸ“‹ ì„ íƒëœ ì„œë¹„ìŠ¤ ëª©ë¡: {selected_services}")
            
            # ì„œë¹„ìŠ¤ ë°ì´í„° ë””ë ‰í† ë¦¬ í™•ì¸
            services_prefix = f"{self._get_user_prefix(user_id)}collections/{collection_id}/services/"
            available_files = []
            
            try:
                # ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  ê°ì²´ ë‚˜ì—´
                logger.info(f"ğŸ“¥ S3ì—ì„œ ì„œë¹„ìŠ¤ ë””ë ‰í† ë¦¬ ì¡°íšŒ: {services_prefix}")
                response = self.s3_client.list_objects_v2(
                    Bucket=self.bucket_name,
                    Prefix=services_prefix
                )
                
                if 'Contents' in response:
                    available_files = [item['Key'] for item in response['Contents']]
                    logger.info(f"ğŸ“¥ S3 ì„œë¹„ìŠ¤ ë””ë ‰í† ë¦¬ì—ì„œ ì°¾ì€ íŒŒì¼: {len(available_files)}ê°œ")
                else:
                    logger.warning(f"âš ï¸ S3 ì„œë¹„ìŠ¤ ë””ë ‰í† ë¦¬ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤: {services_prefix}")
                    
                    # ì„œë¹„ìŠ¤ ë””ë ‰í† ë¦¬ê°€ ë¹„ì–´ìˆìœ¼ë©´ ê¸°ë³¸ ë°ì´í„° ìƒì„±
                    all_services_data = {}
                    for service_key in selected_services:
                        # ë¹ˆ ë°ì´í„° ìƒì„±
                        all_services_data[service_key] = {"status": "collected", "data": {}}
                    
                    # í†µí•© ë°ì´í„° íŒŒì¼ ì €ì¥
                    all_services_key = f"{self._get_user_prefix(user_id)}collections/{collection_id}/all_services.json"
                    logger.info(f"ğŸ“¤ S3ì— ë¹ˆ í†µí•© ì„œë¹„ìŠ¤ ë°ì´í„° ìƒì„± ì‹œì‘")
                    self.s3_client.put_object(
                        Bucket=self.bucket_name,
                        Key=all_services_key,
                        Body=json.dumps(all_services_data),
                        ContentType='application/json'
                    )
                    logger.info(f"ğŸ“¤ S3ì— í†µí•© ì„œë¹„ìŠ¤ ë°ì´í„° ìƒì„± ì™„ë£Œ: {all_services_key}")
                    
                    # ê²°ê³¼ì— ì¶”ê°€
                    result['services_data'] = all_services_data
                    
                    # ì„œë¹„ìŠ¤ ë°ì´í„° ìºì‹œì— ì €ì¥
                    self._set_in_cache('data', user_id, all_services_data, collection_id, 'all')
                    logger.info(f"ğŸ’¾ ì„œë¹„ìŠ¤ ë°ì´í„° ìºì‹œ ì €ì¥ ì™„ë£Œ (ë¹ˆ ë°ì´í„°)")
                    
                    return result
            except Exception as e:
                logger.error(f"âŒ S3 ì„œë¹„ìŠ¤ ë””ë ‰í† ë¦¬ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            
            # ê° ì„œë¹„ìŠ¤ ë°ì´í„° ì¡°íšŒ
            all_services_data = {}
            for service_key in selected_services:
                try:
                    service_data_key = f"{self._get_user_prefix(user_id)}collections/{collection_id}/services/{service_key}.json"
                    logger.info(f"ğŸ“¥ S3ì—ì„œ ì„œë¹„ìŠ¤ ë°ì´í„° ì¡°íšŒ ì‹œë„: {service_key}")
                    
                    service_data_obj = self.s3_client.get_object(Bucket=self.bucket_name, Key=service_data_key)
                    service_data = json.loads(service_data_obj['Body'].read().decode('utf-8'))
                    all_services_data[service_key] = service_data
                    logger.info(f"ğŸ“¥ S3ì—ì„œ ì„œë¹„ìŠ¤ {service_key} ë°ì´í„° ë¡œë“œ ì„±ê³µ")
                except ClientError as e:
                    if e.response['Error']['Code'] == 'NoSuchKey':
                        logger.warning(f"âš ï¸ S3ì—ì„œ ì„œë¹„ìŠ¤ {service_key} ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                        # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë°ì´í„° ìƒì„±
                        all_services_data[service_key] = {"status": "collected", "data": {}}
                    else:
                        logger.error(f"âŒ S3ì—ì„œ ì„œë¹„ìŠ¤ {service_key} ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            
            # ë°ì´í„°ê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
            if not all_services_data:
                logger.warning(f"âš ï¸ ìˆ˜ì§‘ ID {collection_id}ì— ëŒ€í•œ ì„œë¹„ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                # ë¹ˆ ë°ì´í„°ë¼ë„ ìƒì„±
                for service_key in selected_services:
                    all_services_data[service_key] = {"status": "collected", "data": {}}
            
            # í†µí•© ë°ì´í„° íŒŒì¼ ì €ì¥ (í–¥í›„ ì¡°íšŒë¥¼ ìœ„í•´)
            try:
                all_services_key = f"{self._get_user_prefix(user_id)}collections/{collection_id}/all_services.json"
                logger.info(f"ğŸ“¤ S3ì— í†µí•© ì„œë¹„ìŠ¤ ë°ì´í„° ì €ì¥ ì‹œì‘")
                self.s3_client.put_object(
                    Bucket=self.bucket_name,
                    Key=all_services_key,
                    Body=json.dumps(all_services_data),
                    ContentType='application/json'
                )
                logger.info(f"ğŸ“¤ S3ì— í†µí•© ì„œë¹„ìŠ¤ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {all_services_key}")
            except Exception as e:
                logger.error(f"âŒ S3ì— í†µí•© ì„œë¹„ìŠ¤ ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            
            result['services_data'] = all_services_data
            
            # ì„œë¹„ìŠ¤ ë°ì´í„° ìºì‹œì— ì €ì¥
            self._set_in_cache('data', user_id, all_services_data, collection_id, 'all')
            logger.info(f"ğŸ’¾ ì„œë¹„ìŠ¤ ë°ì´í„° ìºì‹œ ì €ì¥ ì™„ë£Œ (ë ˆê±°ì‹œ ë°©ì‹)")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ ë ˆê±°ì‹œ ë°©ì‹ìœ¼ë¡œ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
    
    def list_user_collections(self, user_id):
        """
        ì‚¬ìš©ìì˜ ëª¨ë“  ìˆ˜ì§‘ ë°ì´í„° ëª©ë¡ ì¡°íšŒ
        
        Args:
            user_id: ì‚¬ìš©ì ID
            
        Returns:
            list: ìˆ˜ì§‘ ë°ì´í„° ë©”íƒ€ë°ì´í„° ëª©ë¡ (ìµœì‹ ìˆœ)
        """
        # ìºì‹œ í™•ì¸
        collections, cache_hit = self._get_from_cache('collections', user_id)
        if cache_hit:
            logger.info(f"âœ… ì»¬ë ‰ì…˜ ëª©ë¡ ìºì‹œ íˆíŠ¸ ì„±ê³µ: {user_id}")
            logger.info(f"ğŸ“Š ë°ì´í„° ì†ŒìŠ¤: ìºì‹œ (ì»¬ë ‰ì…˜ ëª©ë¡)")
            return collections
        else:
            logger.info(f"âŒ ì»¬ë ‰ì…˜ ëª©ë¡ ìºì‹œ íˆíŠ¸ ì‹¤íŒ¨: {user_id}")
            logger.info(f"ğŸ“¥ S3ì—ì„œ ì»¬ë ‰ì…˜ ëª©ë¡ ì¡°íšŒ ì‹œì‘")
        
        try:
            collections = []
            prefix = f"{self._get_user_prefix(user_id)}collections/"
            
            # S3ì—ì„œ ë©”íƒ€ë°ì´í„° íŒŒì¼ ëª©ë¡ ì¡°íšŒ
            paginator = self.s3_client.get_paginator('list_objects_v2')
            for page in paginator.paginate(Bucket=self.bucket_name, Prefix=prefix, Delimiter='/'):
                if 'CommonPrefixes' in page:
                    for common_prefix in page['CommonPrefixes']:
                        collection_prefix = common_prefix['Prefix']
                        collection_id = collection_prefix.split('/')[-2]  # collections/{collection_id}/
                        
                        # ë©”íƒ€ë°ì´í„° ì¡°íšŒ
                        try:
                            # ìºì‹œ í™•ì¸
                            metadata, cache_hit = self._get_from_cache('metadata', user_id, collection_id)
                            if cache_hit:
                                collections.append(metadata)
                                continue
                            
                            metadata_key = f"{collection_prefix}metadata.json"
                            metadata_obj = self.s3_client.get_object(Bucket=self.bucket_name, Key=metadata_key)
                            metadata = json.loads(metadata_obj['Body'].read().decode('utf-8'))
                            collections.append(metadata)
                            
                            # ë©”íƒ€ë°ì´í„° ìºì‹œì— ì €ì¥
                            self._set_in_cache('metadata', user_id, metadata, collection_id)
                        except ClientError as e:
                            if e.response['Error']['Code'] == 'NoSuchKey':
                                logger.warning(f"ìˆ˜ì§‘ ID {collection_id}ì˜ ë©”íƒ€ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                raise
            
            # ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬
            collections.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
            
            # ìºì‹œì— ì €ì¥
            self._set_in_cache('collections', user_id, collections)
            logger.info(f"ğŸ’¾ ì»¬ë ‰ì…˜ ëª©ë¡ ìºì‹œ ì €ì¥ ì™„ë£Œ: {user_id}")
            logger.info(f"ğŸ“Š ë°ì´í„° ì†ŒìŠ¤: S3 (ì»¬ë ‰ì…˜ ëª©ë¡)")
            
            return collections
            
        except Exception as e:
            logger.error(f"ì‚¬ìš©ì ìˆ˜ì§‘ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return []
    
    def get_service_data(self, user_id, collection_id, service_type):
        """
        íŠ¹ì • ìˆ˜ì§‘ IDì˜ íŠ¹ì • ì„œë¹„ìŠ¤ ë°ì´í„°ë§Œ ì¡°íšŒ
        
        Args:
            user_id: ì‚¬ìš©ì ID
            collection_id: ìˆ˜ì§‘ ID
            service_type: ì„œë¹„ìŠ¤ íƒ€ì… (ec2, s3 ë“±)
            
        Returns:
            dict: í•´ë‹¹ ì„œë¹„ìŠ¤ì˜ ë°ì´í„°
        """
        try:
            # ìºì‹œ í™•ì¸
            service_data, cache_hit = self._get_from_cache('data', user_id, collection_id, service_type)
            if cache_hit:
                logger.info(f"âœ… ì„œë¹„ìŠ¤ ë°ì´í„° ìºì‹œ íˆíŠ¸ ì„±ê³µ: {collection_id}/{service_type}")
                return service_data
            
            # ì „ì²´ ë°ì´í„° ì¡°íšŒ
            collection_data = self.get_collection_data(user_id, collection_id)
            if not collection_data or 'services_data' not in collection_data:
                logger.warning(f"âŒ ìˆ˜ì§‘ ID {collection_id}ì˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # í•´ë‹¹ ì„œë¹„ìŠ¤ ë°ì´í„°ë§Œ ì¶”ì¶œ
            if service_type in collection_data['services_data']:
                service_data = collection_data['services_data'][service_type]
                
                # ìºì‹œì— ì €ì¥
                self._set_in_cache('data', user_id, service_data, collection_id, service_type)
                logger.info(f"ğŸ’¾ ì„œë¹„ìŠ¤ ë°ì´í„° ìºì‹œ ì €ì¥ ì™„ë£Œ: {collection_id}/{service_type}")
                
                return service_data
            else:
                logger.warning(f"âŒ ìˆ˜ì§‘ ID {collection_id}ì— ì„œë¹„ìŠ¤ {service_type} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None
                
        except Exception as e:
            logger.error(f"âŒ ì„œë¹„ìŠ¤ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
    
    def delete_collection(self, user_id, collection_id):
        """
        íŠ¹ì • ìˆ˜ì§‘ ë°ì´í„° ì‚­ì œ
        
        Args:
            user_id: ì‚¬ìš©ì ID
            collection_id: ìˆ˜ì§‘ ID
            
        Returns:
            bool: ì‚­ì œ ì„±ê³µ ì—¬ë¶€
        """
        try:
            prefix = f"{self._get_user_prefix(user_id)}collections/{collection_id}/"
            
            # í•´ë‹¹ ì ‘ë‘ì‚¬ì˜ ëª¨ë“  ê°ì²´ ì‚­ì œ
            paginator = self.s3_client.get_paginator('list_objects_v2')
            for page in paginator.paginate(Bucket=self.bucket_name, Prefix=prefix):
                if 'Contents' in page:
                    objects_to_delete = [{'Key': obj['Key']} for obj in page['Contents']]
                    if objects_to_delete:
                        self.s3_client.delete_objects(
                            Bucket=self.bucket_name,
                            Delete={'Objects': objects_to_delete}
                        )
            
            # ìºì‹œ ë¬´íš¨í™”
            self._invalidate_cache('collections', user_id)
            self._invalidate_cache('all', user_id, collection_id)
            
            logger.info(f"ì‚¬ìš©ì {user_id}ì˜ ìˆ˜ì§‘ ë°ì´í„° {collection_id}ë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")
            return True
            
        except Exception as e:
            logger.error(f"ìˆ˜ì§‘ ë°ì´í„° ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False